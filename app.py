# -*- coding: utf-8 -*-
"""Copy of vpa02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZlLyA8n-CIwwBdq4Mjcbj5571gLXyIXn
"""

import gradio as gr
import pandas as pd
import numpy as np
import json
from googleapiclient.discovery import build
import plotly.express as px
from datetime import datetime, timedelta
import isodate  # Required for parsing ISO 8601 duration format

# Function to parse ISO 8601 duration into a human-readable format
def parse_duration(duration_iso):
    duration = isodate.parse_duration(duration_iso)
    return duration

# Function to fetch YouTube data with pagination handling
def get_youtube_data(api_key, search_keyword, start_date, end_date):
    try:
        youtube = build('youtube', 'v3', developerKey=api_key)

        # Format dates in ISO 8601 format
        start_date_str = f"{start_date}T00:00:00Z"
        end_date_str = f"{end_date}T23:59:59Z"

        next_page_token = None
        video_data = []

        # Keep fetching videos as long as there are more pages
        while True:
            # Define search parameters
            search_response = youtube.search().list(
                q=search_keyword,
                part='id,snippet',
                maxResults=50,
                type='video',
                publishedAfter=start_date_str,
                publishedBefore=end_date_str,
                pageToken=next_page_token
            ).execute()

            for search_result in search_response['items']:
                video_id = search_result['id']['videoId']
                video_details = youtube.videos().list(part='statistics,contentDetails', id=video_id).execute()

                for video in video_details['items']:
                    view_count = int(video['statistics'].get('viewCount', 0))
                    comment_count = int(video['statistics'].get('commentCount', 0))
                    like_count = int(video['statistics'].get('likeCount', 0))
                    duration_iso = video['contentDetails'].get('duration')
                    duration = parse_duration(duration_iso)  # Convert ISO 8601 to timedelta

                    # Calculate engagement rate (likes + comments) / views * 100
                    engagement_rate = ((like_count + comment_count) / view_count * 100) if view_count > 0 else 0

                    video_data.append({
                        'Video ID': video_id,
                        'Title': search_result['snippet']['title'],
                        'Published At': search_result['snippet']['publishedAt'],
                        'View Count': view_count,
                        'Comment Count': comment_count,
                        'Like Count': like_count,
                        'Engagement Rate (%)': engagement_rate,
                        'Duration': str(duration)  # Convert timedelta to string for display
                    })

            # Get next page token to fetch more videos
            next_page_token = search_response.get('nextPageToken')
            if not next_page_token:
                break

        df = pd.DataFrame(video_data)
        return df, None

    except Exception as e:
        return None, str(e)

# Function to generate Plotly plots (line, bar, or histogram)
def generate_plot(df, column, plot_type):
    if plot_type == "line":
        fig = px.line(df, x='Video ID', y=column, title=f"{column} per video", hover_data=['Video ID', column])
    elif plot_type == "bar":
        fig = px.bar(df, x='Video ID', y=column, title=f"{column} Bar Plot", hover_data=['Video ID', column])
    elif plot_type == "hist":
        fig = px.histogram(df, x=column, nbins=10, title=f"{column} Histogram", hover_data=['Video ID', column])

    fig.update_layout(xaxis_title='Video ID', yaxis_title=column, xaxis_tickangle=-90)
    return fig

#########
# Function to save metrics as a TXT file with JSON content
def save_metrics_to_txt(metrics, filename="search_metrics.txt"):
    with open(filename, 'w') as txt_file:
        json.dump(metrics, txt_file, indent=4)  # Save JSON as text in the file
    return filename
########
# Custom function to handle non-serializable data types (e.g., numpy int64)
def convert_to_serializable(obj):
    if isinstance(obj, np.int64):
        return int(obj)
    raise TypeError(f"Object of type {obj.__class__.__name__} is not JSON serializable")
########
# Main analysis function to fetch data and generate metrics
def analyze_youtube(api_key, search_keyword, start_date, end_date):
    df, error = get_youtube_data(api_key, search_keyword, start_date, end_date)

    if error:
        return error, None, None

    if df.empty:
        return "No data found for the given search parameters.", None, None

    # Calculate total metrics
    metrics = {
        'Search Keyword': search_keyword,
        'Total Videos': len(df),
        'Total Views': df['View Count'].sum(),
        'Total Comments': df['Comment Count'].sum(),
        'Total Likes': df['Like Count'].sum(),
        'Average Engagement Rate (%)': df['Engagement Rate (%)'].mean()
    }

    return metrics, df
######
    # Save metrics to a TXT file
    filename = save_metrics_to_txt(metrics, filename=f"{search_keyword}_metrics.txt")

    return metrics, filename
#####


# Gradio Blocks UI
with gr.Blocks() as demo:
    gr.Markdown("# View Point Analytics")

    # Input section for YouTube API, search term, and date range
    with gr.Row():
        api_key = gr.Textbox(label="YouTube API Key", type="password")
        search_keyword = gr.Textbox(label="Search Keyword")
        start_date = gr.Textbox(label="Start Date (YYYY-MM-DD)", value=(datetime.now() - timedelta(days=30)).date().isoformat())
        end_date = gr.Textbox(label="End Date (YYYY-MM-DD)", value=datetime.now().date().isoformat())

    analyze_button = gr.Button("Analyze")

    # Metrics output and video details
    metrics_output = gr.JSON(label="Search Metrics")
    video_details_output = gr.Dataframe(label="Video Details")

    #####
    # Output for metrics and TXT file download
    #output_metrics = gr.JSON(label="Search Metrics")
    txt_download_button = gr.File(label="Download TXT File")
    ###

    # Layout for plots and plot type options
    with gr.Row():
        # The views plot on the left
        with gr.Column(scale=5):
            views_plot_output = gr.Plot(label="Views Plot")
        with gr.Column(scale=1):
            views_plot_type = gr.Radio(choices=["line", "bar", "hist"], value="line", label="Plot Type")

    with gr.Row():
        # The likes plot on the left
        with gr.Column(scale=5):
            likes_plot_output = gr.Plot(label="Likes Plot")
        with gr.Column(scale=1):
            likes_plot_type = gr.Radio(choices=["line", "bar", "hist"], value="line", label="Plot Type")

    with gr.Row():
        # The comments plot on the left
        with gr.Column(scale=5):
            comments_plot_output = gr.Plot(label="Comments Plot")
        with gr.Column(scale=1):
            comments_plot_type = gr.Radio(choices=["line", "bar", "hist"], value="line", label="Plot Type")

    with gr.Row():
        # The engagement rate plot on the left
        with gr.Column(scale=5):
            engagement_plot_output = gr.Plot(label="Engagement Rate Plot")
        with gr.Column(scale=1):
            engagement_plot_type = gr.Radio(choices=["line", "bar", "hist"], value="line", label="Plot Type")

    # Download buttons
    #download_metrics_button = gr.Button("Download Metrics CSV")
    #download_videos_button = gr.Button("Download Video Details CSV")

    # Event: Button to trigger the analysis and get metrics
    def main_analyze(api_key, search_keyword, start_date, end_date):
        metrics, df = analyze_youtube(api_key, search_keyword, start_date, end_date)

        if metrics is None or df is None:
          return "Error during analysis", None, None

        # Save metrics as a text (JSON) file
        filename = "search_metrics.txt"
        with open(filename, 'w') as f:
          json.dump(metrics, f, default=convert_to_serializable)  # Save the metrics in JSON format to a text file

        return metrics, filename, df

    analyze_button.click(main_analyze,
                         inputs=[api_key, search_keyword, start_date, end_date],
                         outputs=[metrics_output, txt_download_button, video_details_output],
                         show_progress=True)

    # Function to update the plots
    def plot_update(df, views_plot_type, likes_plot_type, comments_plot_type, engagement_plot_type):
        views_plot = generate_plot(df, 'View Count', views_plot_type)
        likes_plot = generate_plot(df, 'Like Count', likes_plot_type)
        comments_plot = generate_plot(df, 'Comment Count', comments_plot_type)
        engagement_plot = generate_plot(df, 'Engagement Rate (%)', engagement_plot_type)

        return views_plot, likes_plot, comments_plot, engagement_plot

    # Trigger plot updates when the plot type changes
    views_plot_type.change(
        lambda plot_type, df: plot_update(df, plot_type, likes_plot_type.value, comments_plot_type.value, engagement_plot_type.value),
        inputs=[views_plot_type, video_details_output],
        outputs=[views_plot_output, likes_plot_output, comments_plot_output, engagement_plot_output]
    )

    likes_plot_type.change(
        lambda plot_type, df: plot_update(df, views_plot_type.value, plot_type, comments_plot_type.value, engagement_plot_type.value),
        inputs=[likes_plot_type, video_details_output],
        outputs=[views_plot_output, likes_plot_output, comments_plot_output, engagement_plot_output]
    )

    comments_plot_type.change(
        lambda plot_type, df: plot_update(df, views_plot_type.value, likes_plot_type.value, plot_type, engagement_plot_type.value),
        inputs=[comments_plot_type, video_details_output],
        outputs=[views_plot_output, likes_plot_output, comments_plot_output, engagement_plot_output]
    )

    engagement_plot_type.change(
        lambda plot_type, df: plot_update(df, views_plot_type.value, likes_plot_type.value, comments_plot_type.value, plot_type),
        inputs=[engagement_plot_type, video_details_output],
        outputs=[views_plot_output, likes_plot_output, comments_plot_output, engagement_plot_output]
    )

    # Function to save video details to a CSV file and return the file path for download
    def save_video_details_to_csv(df):
        file_path = "video_details.csv"
        df.to_csv(file_path, index=False)
        return file_path

    download_videos_button = gr.Button("Download Video Details CSV")
    video_file_output = gr.File()  # This will show the download link

    # Event: Button to download video details CSV
    download_videos_button.click(save_video_details_to_csv, inputs=[video_details_output], outputs=[video_file_output])


# Launch Gradio app
demo.launch(share=True, debug=True)